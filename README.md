# LiLa GPT

The project's goal is to finetune a Latin GPT on the Latin information present in the [LiLa Knowledge Graph](https://lila-erc.eu/sparql/). 

Our first intended waypoint is to train a small model on the raw token information present inside the graph. (Tokenization details still pending...)

A later goal will be to finetune a larger LLM (e.g. LlaMa, DeepSeek, Mistral, Gemma...) on the graph, while also incorporating the linguistic information present inside the graph. (Lemma, part-of-speech, cases, dependency information....)
